<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Prof. Frank Dehne</title>


  

  
  
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"></head><body style="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255);" alink="#000000" link="#000000" vlink="#000000">
<table border="0" width="100%">

  <tbody>
    <tr>
      <td height="27" width="45%">
      <h2>COMP 5704: Parallel Algorithms and Applications in Data Science<br>
</h2>
      </td>
      <td height="27" width="10%">
      <p><br>
      </p>
      </td>
      <td height="27" width="45%">
      <p><b>School of Computer Science</b><br>
      <b>Carleton University, Ottawa, Canada</b></p>
      </td>
    </tr>
  </tbody>
</table>

<hr noshade="noshade">
<h2><font color="#005128">Project Title: </font><font><font color="#005128">Distributed method for training of Artificial Neural Networks</font></font></h2>

<h2><font><font color="#005128">Name: Seyed Omid Davoudi</font></font></h2>

<h2><font><font color="#005128">E-Mail: omiddavoudi at cmail.carleton.ca</font></font></h2>



<hr noshade="noshade">
<b><font color="#005128">Project Outline:</font></b> Machine Learning is currently experiencing a boom partly because of the recent advances in Deep Neural Networks. As time goes on, the datasets used for training these networks are getting larger and harder to handle. On the other side, the physical challenges of creating faster parallel processing hardware suitable for such tasks (GPUs, TPUs, etc.) has led to the growing interest in distributed methods for training neural networks.<br>
One of the interesting neural network architectures that has recently gained traction is that of the Generative Adversarial Network (GAN). GANs are used to create new and never-seen-before data points from observing a dataset, for example, generating pictures of cats after being trained on a dataset of cat images. These networks are notoriously hard to train and common distributed schemes for training neural nets have given poor results. This project aims to replacate the recent work of Hardy, Merrer and Sericola on a new architecture designed specifically to train GANs in a distributed manner.<br>
<p><b><font color="#005128">Startup Paper(s):</font></b> Click to go to page : <a href="https://ieeexplore-ieee-org.proxy.library.carleton.ca/document/8821025">MD-GAN: Multi-Discriminator Generative Adversarial Networks for Distributed Datasets</a></p>

<p><b><font color="#005128">Deliverables:</font></b></p>

<ul>

  <li>
    <div align="left"><!--<a href="Literature_Review.pdf">--><font color="#000000">Literature Review</font></a> (PDF file created from
LATEX template)</div>
  </li>
  <li>
    <div align="left"><!--<a href="Presentation_Outline.pdf">--><font color="#000000">Presentation Outline</font></a> (PDF file created from
LATEX template)</div>
  </li>
  <li>
    <div align="left"> <!--<a href="Slide_Presentation.ppt">--><font color="#000000">Slide Presentation</font></a> (PowerPoint File) incl.
Question Sheet </div>
  </li>
  <li>
    <div align="left"><!--<a href="Final_Paper.pdf">--><font color="#000000">Final
Paper</font></a> (PDF file created from LATEX template)</div>
  </li>
  <li><!--<a href="Code_and_Data">--><font color="#000000">Code and Data</font></a>
(put all code, data, etc. into this directory)</li>
</ul>

<p><b><font color="#005128">Relevant References:</font></b></p>

<ul>

  <li>list all relevant papers and include links to their PDF files</li>
</ul>

</body></html>
