
@article{DEL07,
	author={F. Dehne and T. Eavis and B. Liang},
	title={Compressing Data Cubes in Parallel {OLAP} Systems},
	abstract={},
	journal={Data Science Journal},
	volume={6},
	number={},
	year={2007},
	pages={S184-S197}
} ---------------------------------
 
@article{PD07,
	author={S. Pitre and F. Dehne and A. Chan and J. Cheetham and A. Duong and A. Emili and M. Gebbia and J. Greenblatt and M. Jessulat and N. Krogan and X. Luo and A. Golshani},
	title={{PIPE}: a protein-protein interaction prediction engine based on the re-occurring short polypeptide sequences between known interacting protein pairs},
	abstract={Paper classified as "Highly accessed". 1989 downloads in the first five months. Journal impact factor: 4.96.},
	journal={BMC Bioinformatics},
	volume={7},
	number={},
	year={2006, available via PubMed at http://www.biomedcentral.com/pubmed/16872538},
	pages={365 (15 pages)}
} ---------------------------------

@article{DER07,
	author={F. Dehne and T. Eavis and A. Rau-Chaplin},
	title={The {cgmCUBE} Project: Optimizing Parallel Data Cube Generation For {ROLAP}},
	abstract={},
	journal={Distributed and Parallel Databases},
	volume={19},
	number={1},
	year={2006},
	pages={29-62}
} --------------------------------- 

@inproceedings{LDR07,
	author={M. Lawrence and F. Dehne and A. Rau-Chaplin},
	title={Implementing {OLAP} Query Fragment Aggregation and Recombination for the {OLAP} Enabled Grid},
	abstract={http://www.cs.unb.ca/profs/aubanel/hpgc/},
	booktitle={Proc. International Parallel and Distributed Processing Symposium (IPDPS), High-Performance Grid Computing Workshop},
	year={2007},
	publisher={IEEE Comp. Soc. Dig. Library},
	pages={1-8}
} ---------------------------------

@inproceedings{DLX06,
	author={F. Dehne and M. Langston and X. Luo and S. Pitre and P. Shaw and Y. Zhang},
	title={The Cluster Editing Problem: Implementations and Experiments},
	abstract={Zuerich, Switzerland, 2006},
	booktitle={Proc. Int. Workshop on Parameterized and Exact Computation (IWPEC)},
	year={2006},
	publisher={Springer LNCS 4169},
	pages={13-24}
} ---------------------------------


@inproceedings{CDE06,
	author={Y. Chen and F. Dehne and T. Eavis and D. Green and A. Rau-Chaplin and E. Sithirasenan},
	title={{cgmOLAP}: Efficient Parallel Generation and Querying of Terabyte Size {ROLAP} Data Cubes},
	abstract={Atlanta, GA, 2006},
	booktitle={Proc. 22nd Int. Conf. on Data Engineering (ICDE)},
	year={2006},
	publisher={IEEE Comp. Soc. Dig. Library},
	pages={164-164}
} ---------------------------------

@inproceedings{DFL06,
	author={F. Dehne and M. Fellows and M. Langston and F. Rosamond and K. Stevens},
	title={An $O(2^{O(k)} n^3 )$ {FPT} algorithm for the undirected feedback vertex set problem},
	abstract={Kunming, China},
	booktitle={Proc. 11th Int. Computing and Combinatorics Conf. (COCOON)},
	year={2005},
	publisher={Springer LNCS 3595},
	pages={859-869}
} ---------------------------------


@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{mescheder2018training,
  title={Which training methods for GANs do actually converge?},
  author={Mescheder, Lars and Geiger, Andreas and Nowozin, Sebastian},
  journal={arXiv preprint arXiv:1801.04406},
  year={2018}
}

@article{Li2014,
abstract = {We propose a parameter server framework for distributed machine learning problems. Both data and workloads are distributed over worker nodes, while the server nodes maintain globally shared parameters, represented as dense or sparse vectors and matrices. The framework manages asynchronous data communication between nodes, and supports flexible consistency models, elastic scalability, and continuous fault tolerance. To demonstrate the scalability of the proposed frame-work, we show experimental results on petabytes of real data with billions of examples and parameters on prob-lems ranging from Sparse Logistic Regression to Latent Dirichlet Allocation and Distributed Sketching.},
author = {Li, Mu and Andersen, David G and Park, Jun Woo and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-yiing and Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr},
file = {:C$\backslash$:/Users/omid/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2014 - Scaling Distributed Machine Learning with the Parameter Server.pdf:pdf},
isbn = {9781931971164},
journal = {Proceedings of OSDI},
mendeley-groups = {Parallel},
pages = {583--598},
title = {{Scaling Distributed Machine Learning with the Parameter Server}},
year = {2014}
}

@article{cano2016towards,
  title={Towards geo-distributed machine learning},
  author={Cano, Ignacio and Weimer, Markus and Mahajan, Dhruv and Curino, Carlo and Fumarola, Giovanni Matteo},
  journal={arXiv preprint arXiv:1603.09035},
  year={2016}
}

@article{kearns1998efficient,
  title={Efficient noise-tolerant learning from statistical queries},
  author={Kearns, Michael},
  journal={Journal of the ACM (JACM)},
  volume={45},
  number={6},
  pages={983--1006},
  year={1998},
  publisher={ACM}
}

@inproceedings{hsieh2017gaia,
  title={Gaia: Geo-Distributed Machine Learning Approaching $\{$LAN$\}$ Speeds},
  author={Hsieh, Kevin and Harlap, Aaron and Vijaykumar, Nandita and Konomis, Dimitris and Ganger, Gregory R and Gibbons, Phillip B and Mutlu, Onur},
  booktitle={14th $\{$USENIX$\}$ Symposium on Networked Systems Design and Implementation ($\{$NSDI$\}$ 17)},
  pages={629--647},
  year={2017}
}

\ignorecitefornumbering{}
